[
{
	"uri": "/03-nucalm-middle/01-helloworld/",
	"title": "HelloWorld蓝图",
	"tags": [],
	"description": "创建一个最简单的蓝图",
	"content": "这个lab的目标：\n 蓝图使用上面的CentOS7的模板镜像 在创建工作流里生成一个包含Hello World字符串的文件/helloworld.txt 这个蓝图可以生成自定义配置的n台虚拟机 运行这个蓝图生成3个虚拟机 使用Stop工作流，poweroff这三个虚拟机 使用Start工作流，poweron这三个虚拟机 使用Delete工作流删除这三个虚拟机实例  操作步骤如下。\n点击左侧的第二个蓝图按钮，点击 创建应用蓝图 按钮。 选择这个蓝图部署的项目名称，点击处理按钮。 点击配置按钮，填写应用配置信息。 填写蓝图名称和描述。 点击Credentials按钮，输入一个root用户信息，用于登录自动化生成的虚拟机，例如 root / nutanix/4u , 输入完密码后再空白处点击一下，在点击密码框中右侧的眼睛按钮，确认保存的密码。点击 back按钮。 点击 Save 按钮保存当前的配置，其实也是检查当前配置信息的正确性，否则保存不会成功。 点击右下角的Create按钮，配置创建工作流，输入如图所示的信息。选择的 Image 模板名称是上个步骤里生成的模板。\n选择该蓝图的这个服务VM的配置信息，包括用于ssh登录的账户信息。 点击 save 按钮保存蓝图配置，点击Launch按钮，部署这个蓝图。 输入此次应用部署的名称，点击 create 按钮。 观察当前这个蓝图部署的状态。 点击 Manager ，点击 Create 创建工作流右侧的眼睛按钮，查看当前自动化工作流执行的进度和状态。 全部都是绿色表示一切正常。 在PC的虚拟机查看控制台刚才的部署生成的vm和它的状态。 SSH登录到这个虚拟机，运行下面的命令查看目标的文件是否部署成功。\n[root@localhost ~]# ls / bin etc lib mnt root srv usr boot helloworld.txt lib64 opt run sys var dev home media proc sbin tmp [root@localhost ~]# cat /helloworld.txt hello world [root@localhost ~]#  以上步骤的验收标准： 可以登录用户蓝图生成的vm，能看到目标的文件。 "
},
{
	"uri": "/04-nucalm-advance/01-docker-swarm-cluster/",
	"title": "一键安装Docker Swarm群集",
	"tags": [],
	"description": "安装和部署Docker Swarm群集，包含高可用性等。",
	"content": " 构建中\u0026hellip;.\n这个lab的目标：\n 蓝图使用上面的CentOS7的模板镜像 在创建工作流里生成一个包含Hello World字符串的文件/helloworld.txt 这个蓝图可以生成自定义配置的n台虚拟机 运行这个蓝图生成3个虚拟机 使用Stop工作流，poweroff这三个虚拟机 使用Start工作流，poweron这三个虚拟机 使用Delete工作流删除这三个虚拟机实例  为Docker Swarm群集配置Nutanix持久存储 本文介绍如何用Docker卷插件的方式，给Docker Swarm的群集挂载Nutanix存储。Nutanix Container Volume Plug-in 简称DVP，可以给容器提供数据持久化的功能。\n本文使用ownCloud网盘应用做功能测试。测试的过程如下，安装部署Docker Datacenter，配置好群集，在UCP的界面里调用DVP插件建持久的数据卷，建立ownCloud服务，部署和测试该服务。\nNutanix DVP (Docker Volume Plug-in)安装和配置 这一部分描述DVP的安装部署过程，需要连接互联网；安装调试完毕之后，作虚拟机的镜像模板使用。这样Docker Swarm的其它节点也都不需要重复这个步骤了。\n本文使用的是Docker社区文档稳定版 17.03.1-ce ；本文使用的OS是CentOS 7.3。所Docker安装的版本如下：\n[root@centos7-temp]# docker version Client: Version: 17.03.1-ce API version: 1.27 Go version: go1.7.5 Git commit: c6d412e Built: Mon Mar 27 17:05:44 2017 OS/Arch: linux/amd64 Server: Version: 17.03.1-ce API version: 1.27 (minimum version 1.12) Go version: go1.7.5 Git commit: c6d412e Built: Mon Mar 27 17:05:44 2017 OS/Arch: linux/amd64 Experimental: false [root@centos7-temp]# rpm -qa|grep docker docker-ce-17.03.1.ce-1.el7.centos.x86_64 docker-ce-selinux-17.03.1.ce-1.el7.centos.noarch  本文使用的Docker 安装yum源如下：\n[root@centos7-temp]# cat /etc/yum.repos.d/docker-ce.repo [docker-ce-stable] name=Docker CE Stable - $basearch baseurl=https://download.docker.com/linux/centos/7/$basearch/stable enabled=1 gpgcheck=1 gpgkey=https://download.docker.com/linux/centos/gpg [docker-ce-stable-debuginfo] name=Docker CE Stable - Debuginfo $basearch baseurl=https://download.docker.com/linux/centos/7/debug-$basearch/stable enabled=0 gpgcheck=1 gpgkey=https://download.docker.com/linux/centos/gpg [docker-ce-stable-source] name=Docker CE Stable - Sources baseurl=https://download.docker.com/linux/centos/7/source/stable enabled=0 gpgcheck=1 gpgkey=https://download.docker.com/linux/centos/gpg [docker-ce-edge] name=Docker CE Edge - $basearch baseurl=https://download.docker.com/linux/centos/7/$basearch/edge enabled=0 gpgcheck=1 gpgkey=https://download.docker.com/linux/centos/gpg [docker-ce-edge-debuginfo] name=Docker CE Edge - Debuginfo $basearch baseurl=https://download.docker.com/linux/centos/7/debug-$basearch/edge enabled=0 gpgcheck=1 gpgkey=https://download.docker.com/linux/centos/gpg [docker-ce-edge-source] name=Docker CE Edge - Sources baseurl=https://download.docker.com/linux/centos/7/source/edge enabled=0 gpgcheck=1 gpgkey=https://download.docker.com/linux/centos/gpg [docker-ce-test] name=Docker CE Test - $basearch baseurl=https://download.docker.com/linux/centos/7/$basearch/test enabled=0 gpgcheck=1 gpgkey=https://download.docker.com/linux/centos/gpg [docker-ce-test-debuginfo] name=Docker CE Test - Debuginfo $basearch baseurl=https://download.docker.com/linux/centos/7/debug-$basearch/test enabled=0 gpgcheck=1 gpgkey=https://download.docker.com/linux/centos/gpg [docker-ce-test-source] name=Docker CE Test - Sources baseurl=https://download.docker.com/linux/centos/7/source/test enabled=0 gpgcheck=1 gpgkey=https://download.docker.com/linux/centos/gpg  本机所使用的所有安装源如下：\n[root@centos7-temp]# yum repolist Loaded plugins: fastestmirror Loading mirror speeds from cached hostfile * base: mirrors.aliyun.com * epel: mirrors.aliyun.com * extras: mirrors.aliyun.com * updates: mirrors.aliyun.com repo id repo name status base/7/x86_64 CentOS-7 - Base - mirrors.aliyun.com 9,363 docker-ce-stable/x86_64 Docker CE Stable - x86_64 4 epel/x86_64 Extra Packages for Enterprise Linux 7 - x86_64 11,808 extras/7/x86_64 CentOS-7 - Extras - mirrors.aliyun.com 381 updates/7/x86_64 CentOS-7 - Updates - mirrors.aliyun.com 1,859 repolist: 23,415  安装docker引擎，并启动服务，并校验服务状态。安装过程参考如下：\n[root@centos7-temp]# yum install -y docker-ce [root@centos7-temp]# systemctl enable docker [root@centos7-temp]# systemctl start docker [root@centos7-temp]# systemctl status docker ● docker.service - Docker Application Container Engine Loaded: loaded (/usr/lib/systemd/system/docker.service; enabled; vendor preset: disabled) Active: active (running) since Tue 2017-06-20 20:30:49 CST; 19min ago Docs: https://docs.docker.com Main PID: 875 (dockerd) CGroup: /system.slice/docker.service ├─ 875 /usr/bin/dockerd ├─ 942 docker-containerd -l unix:///var/run/docker/libcontainerd/docker-containerd.sock --metrics-in... ├─2008 docker-containerd-shim 0ca2346b6126de702fb4dda5f807c0a69a402eb643f15c142730277d0eb7bbcb /var/... └─0ca2346b6126de702fb4dda5f807c0a69a402eb643f15c142730277d0eb7bbcb └─2038 /usr/bin/python /code/main.py --prism-ip 10.68.69.22 --dataservices-ip 10.68.69.23 --prism-...  到目前为止，Docker安装配置完成。\n下面开始安装DVP，安装和配置过程参考页面。\nhttps://store.docker.com/plugins/nutanix-dvp-docker-volume-plug-in\n下面是给操作系统安装iscsi initiator服务的参考步骤：\nyum install -y iscsi-initiator-utils systemd-tmpfiles --create systemctl start iscsid systemctl enable iscsid systemctl status iscsid ● iscsid.service - Open-iSCSI Loaded: loaded (/usr/lib/systemd/system/iscsid.service; enabled; vendor preset: disabled) Active: active (running) since Tue 2017-06-20 20:30:46 CST; 24min ago Docs: man:iscsid(8) man:iscsiadm(8) Main PID: 888 (iscsid) CGroup: /system.slice/iscsid.service ├─882 /usr/sbin/iscsid └─888 /usr/sbin/iscsid Jun 20 20:30:46 centos7-temp.zenlab.local systemd[1]: Starting Open-iSCSI... Jun 20 20:30:46 centos7-temp.zenlab.local iscsid[878]: iSCSI logger with pid=882 started! Jun 20 20:30:46 centos7-temp.zenlab.local systemd[1]: Failed to read PID from file /var/run/iscsid.pid: Inva...ent Jun 20 20:30:46 centos7-temp.zenlab.local systemd[1]: Started Open-iSCSI. Jun 20 20:30:47 centos7-temp.zenlab.local iscsid[882]: iSCSI daemon with pid=888 started! Hint: Some lines were ellipsized, use -l to show in full.   解释一下DVP的工作原理是，它是让Docker主机通过iSCSI协议连接Nutanix的存储服务。DVP插件的配置里包含了连接存储服务和存储容器（这个容器是Nutanix的存储术语，非Docker说的容器）的相关信息。这样Docker主机上用该卷插件建立的数据卷都会指向Nutanix后台的存储容器中；数据通过iSCSI协议连接Nutanix存储服务的时候，就可以利用到Nutanix群集提供的负载均衡能力；当数据块写入Nutanix存储池的过程中和之后，就可以利用到到Nutanix存储容器所具备的其它重要特性：数据块2~3副本的高可靠性、冷热数据分成、压缩、去重、纠删码等；而且存储空间对于容器或者Docker Swarm里的服务都是透明和无限容量的。\n 现在做一些安装DVP的准备工作，询问Nutanix系统管理员下面信息：\n 获得Prism 的IP 获得Nutanix群集数据服务的IP，这个IP是群集上的虚拟服务IP 获得群集的用户名和密码 新建一个测试存储容器，获得容器名  参考下面的DVP安装命令：\ndocker plugin install ntnx/nutanix_volume_plugin PRISM_IP=\u0026quot;10.68.69.22\u0026quot; DATASERVICES_IP=\u0026quot;10.68.69.23\u0026quot; PRISM_PASSWORD=\u0026quot;nutanix/4u\u0026quot; PRISM_USERNAME=\u0026quot;admin\u0026quot; DEFAULT_CONTAINER=\u0026quot;ddc-sc1\u0026quot; --alias nutanix  以上的命令执行结果如下：\n[root@centos7-temp]# docker plugin install ntnx/nutanix_volume_plugin PRISM_IP=\u0026quot;10.68.69.22\u0026quot; DATASERVICES_IP=\u0026quot;10.68.69.23\u0026quot; PRISM_PASSWORD=\u0026quot;nutanix/4u\u0026quot; PRISM_USERNAME=\u0026quot;admin\u0026quot; DEFAULT_CONTAINER=\u0026quot;ddc-sc1\u0026quot; --alias nutanix Plugin \u0026quot;ntnx/nutanix_volume_plugin\u0026quot; is requesting the following privileges: - network: [host] - mount: [/dev] - mount: [/lib/modules] - mount: [/etc/iscsi] - mount: [/var/lock/iscsi] - mount: [/proc] - allow-all-devices: [true] - capabilities: [CAP_SYS_ADMIN CAP_SYS_PTRACE CAP_IPC_LOCK CAP_IPC_OWNER CAP_NET_ADMIN CAP_MKNOD CAP_SYS_MODULE] Do you grant the above permissions? [y/N] y （输入y，按回车） latest: Pulling from ntnx/nutanix_volume_plugin be892c8cb64d: Download complete Digest: sha256:5a3730ffae077eb6ddc0c125620283d56852528b686cbe42f2f58696eab82c0d Status: Downloaded newer image for ntnx/nutanix_volume_plugin:latest Installed plugin ntnx/nutanix_volume_plugin  确认VDP安装结果，这个插件应该是最新版、启动的状态，如下：\n[root@centos7-temp]# docker plugin ls ID NAME DESCRIPTION ENABLED f0e38fbc11b3 nutanix:latest Nutanix volume plugin for docker true  执行下面的测试，确认DVP工作正常。\n[root@centos7-temp]# docker volume create testvol -d nutanix:latest testvol [root@centos7-temp]# docker volume ls DRIVER VOLUME NAME nutanix:latest testvol [root@centos7-temp]#  回到Nutanix的Prisum界面（主要的群集管理图形化界面）中查看Storage \u0026ndash;\u0026gt; table \u0026ndash;\u0026gt; Volume Group，应该能看到这个命令所创建的名为testvol的数据卷。如下图所示：\n在命令行删除这个测试的卷。\n[root@centos7-temp]# docker volume rm testvol testvol [root@centos7-temp]# docker volume ls DRIVER VOLUME NAME [root@centos7-temp]#  在回到Prisum界面中查看刚才看到的那个卷应该就消失了。到此为止所有节点的DVP部署配置工作就完毕了，并且确认docker服务和DVP功能都很正常。用 sys-unconfig 命令关机，把这个虚拟机在Prisum里面做一个快照备用，也可以在Nutanix的acli命令行里面把它做成一个基础镜像。\n我们已经理解和熟悉了DVP的基本操作，配置和部署，下面开始安装Docker Datacenter；Docker Datacenter的架构图如下所示： 本文安装的架构是：\n 一个 UCP manager 节点 一个 DTR 节点 两个 worker node 节点  在Nutanix的Prisum中用刚才制作的那个快照或者镜像模板，克隆/新建4个虚拟机。虚拟机的参考配置如下：\n 2 vCPU 4GB RAM 50GB Disk  安装UCP（Docker Universal Control Plane）节点 在Nutanix的Prisum中从刚才新建的四个虚拟机中选择一个，Power on开机；ssh登录到操作系统内之后，设定主机名和IP地址。\n安装配置参考文档：https://docs.docker.com/datacenter/ucp/2.1/guides/admin/install/install-offline/#download-the-offline-package\n注意事项，提前下载好安装包，这个tar包里面包含了UCP需要的所有镜像，可以一次性导入到UCP的节点上。\nwget https://packages.docker.com/caas/ucp_images_2.1.4.tar.gz -O docker-datacenter.tar.gz docker load \u0026lt; docker-datacenter.tar.gz  载入完毕后，可以看到如下镜像。\n[root@ucp-master ~]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE docker/ucp-metrics 2.1.4 e3e24ef156bd 3 weeks ago 92.2 MB docker/ucp-swarm 2.1.4 d8b51d6801e5 3 weeks ago 21 MB docker/ucp-hrm 2.1.4 38a19323327d 3 weeks ago 14.8 MB docker/ucp-etcd 2.1.4 9aa382502e19 3 weeks ago 38.5 MB docker/ucp-controller 2.1.4 5a852aa3039e 3 weeks ago 28 MB docker/ucp-dsinfo 2.1.4 66ee9368796a 3 weeks ago 159 MB docker/ucp 2.1.4 7a28dbfc44e4 3 weeks ago 19.1 MB docker/ucp latest 7a28dbfc44e4 3 weeks ago 19.1 MB docker/ucp-cfssl 2.1.4 acdc1f147711 3 weeks ago 15.1 MB docker/ucp-compose 2.1.4 25775e989077 3 weeks ago 32.9 MB docker/ucp-auth-store 2.1.4 f27ad13dee6c 3 weeks ago 58.7 MB docker/ucp-agent 2.1.4 d716a096c331 3 weeks ago 22.5 MB docker/ucp-auth 2.1.4 1f4739cd3c08 3 weeks ago 25.1 MB [root@ucp-master ~]#  安装UCP的命令参考如下：\ndocker run --rm -it --name ucp \\ -v /var/run/docker.sock:/var/run/docker.sock \\ docker/ucp:2.1.4 install \\ --host-address 10.68.69.12 \\ --interactive  以上命令中10.68.69.12是UCP主机的ip地址，建议UCP使用固定IP。以上命令完毕后用浏览器访问这个IP。\n参考以下文档，完成UCP的安装步骤，其中需要到Docker网站获得30天的试用版许可证文件。\nhttps://docs.docker.com/datacenter/ucp/2.1/guides/admin/install/\n能够正常登陆访问UCP之后，在首页下方点击 【Add Node】按钮，获得加其它节点到群集里的命令，参考命令如下：\ndocker swarm join \\ --token SWMTKN-1-1310ah7gzj9e7bk6a5yobo2qyiwf93ybrd29flkved1zqydd6i-7pir0884sag5pjofwzjq5o1um \\ 10.68.69.12:2377  把以上命令记录在写字板中备用。\n加3个节点到群集里 把剩下的三个虚拟机开机，进入操作系统后设定主机名和IP。其中的一个安装DTR（Docker镜像仓库）的节点建议使用固定IP。\n在每个操作系统里面用docker命令确认DVP是否正常。\n docker plugin ls docker volume ls systemctl status iscsid  下面就可以把上一步所记录命令在命令行里面执行以下，完毕之后回到UCP的界面中查看是否它们已经添加成功。如下图所示： 安装DTR-Docker镜像仓库 在UCP首页的下方，找到并点击 【Install DTR】的按钮，取得安装命令（记得从清单中选择固定IP地址的DTR主机）；在登录DTR主机的控制台里面输入这个命令，命令如下：\ndocker run -it --rm \\ docker/dtr:2.2.5 install \\ --ucp-node 10.68.69.12 \\ --ucp-insecure-tls  DTR节点没有离线安装的整合包，它需要联网下载很多相关镜像，如果网络速度不是很快的话，下载和安装的过程需要至少半个小时，过程中还需要输入UCP的管理员，用户名和密码。\n参考文档如： https://docs.docker.com/datacenter/dtr/2.2/guides/admin/install/#step-3-install-dtr\nDTR正常工作了以后，登录建立一个名为owncloud的镜像库，点击【New Rrepository】输入owncloud。 在一个节点上下载owncloud镜像，添加新的tag，上传到这个镜像到镜像库里备用。参考命令如下：\ndocker login dtr.zenlab.local docker pull owncloud docker tag owncloud:latest dtr.zenlab.local/admin/owncloud:latest docker push dtr.zenlab.local/admin/owncloud:latest  注意：如果你的环境中没有DNS，就把dtr.zenlab.local换成DTR的IP地址。\n以上这个步骤主要是方便以后，反复使用和测试这个镜像的可能性，如果所有的节点都有高速的互联网链接，可以忽略以上步骤。\nDocker Swarm群集中使用DVP 这里使用UCP的图形化界面，在一个所有节点都配置和部署了VDP的群集上，给群集挂载外部Nutanix的数据卷。\n登录UCP主页，点击Resource，点击Volumes，点击 【Create Volume】，输入相关参数，如下图所示。图中的sizeMb=500000这个参数是制定VolumeGroup的大小，不设定这个参数的话，默认是10GB。 在到Nutanix的Prism里面查看这个Volume Group是否存在。应该如下图所示：\n部署OwnCloud网盘服务 登录UCP主页，点击 Service ， 点击 【Create a Service】按钮；开始建立这个服务。输入服务名，镜像名；点击 【Next】按钮。\n点击 【Next】按钮。进入 Resource页面，这里需要配置端口和数据卷。 最后点击【Deploy Now】按钮。 部署完毕之后，显示这个服务的状态为正常。 点击这个服务，到这个页面的最下方，找到右下角的发布端口的链接，点击后，就可以看到ownCloud的初始化配置页面了。 输入管理员的用户名和密码，进入之后，上传一些图片，测试一下功能是否正常。\n尝试一些Docker Datacenter的高级功能，如服务的高可用性；同时Nutanix的DVP在底层保障了数据的持久性和完全性。测试步骤如下：\n 找到运行owncloud的容器，删除这个容器 在服务页面查看owncloud服务的状态变化 等ownCloud的状态恢复正常之后 再次登录ownCloud页面 查看和确认刚才上传的文件是否还在  总结 Nutanix是一种融合和了计算、存储和虚拟化（内置KVM）的超融合平台。Nutanix DVP (Docker Volume Plug-in)可以让平台里的容器用上持久化存储服务。DVP不仅可以给单独虚拟机里的容器提供持久卷服务，还能给类似于Docker Swarm的其它容器编排平台提供持久化数据服务功能。我后续的文章还会分享路测试Kubernetes等其它平台。\n以上步骤的验收标准： 可以登录用户蓝图生成的vm，能看到目标的文件。 "
},
{
	"uri": "/05-k8s/01-k8s-cluster/",
	"title": "一键安装K8S群集",
	"tags": [],
	"description": "安装和部署K8S群集，包含高可用性等。",
	"content": "构建中\u0026hellip;.\n这个lab的目标：\n 蓝图使用上面的CentOS7的模板镜像 在创建工作流里生成一个包含Hello World字符串的文件/helloworld.txt 这个蓝图可以生成自定义配置的n台虚拟机 运行这个蓝图生成3个虚拟机 使用Stop工作流，poweroff这三个虚拟机 使用Start工作流，poweron这三个虚拟机 使用Delete工作流删除这三个虚拟机实例  以上步骤的验收标准： 可以登录用户蓝图生成的vm，能看到目标的文件。 "
},
{
	"uri": "/02-nucalm-basic/01-configure-calm/",
	"title": "初始化配置Calm",
	"tags": [],
	"description": "Calm环境的基础配置",
	"content": " AWS账户的配置 由于Calm是多云管理，因此很多已经在Nutanix商店里的蓝图都支持AWS的部署，下面需要配置一个假的AWS账户信息，这样在使用预定义蓝图的时候减少提示信息出现的机会。\nApp页面里，左侧齿轮图标，进入AWS账户配置页面，点击 Add Setting 按钮。\n在这个页面中输入任一的 Access Key ID 和 Secret Access Key 字符串。保证点击Save后正确地保存了一条记录即可。 配置Calm项目 点击左侧最下面的图标，进入项目配置页面，点击 Create Project 按钮。\n输入该项目的相关信息：\n 项目名称：可以是一个应用开发团队，或者一个业务应用一个项目 用户和角色信息：下图设置 ssp_user 组里的所有人的角色是 Developer，可以设置其他的AD用户为其它各种的Role 选中 Local and Cloud Resource 选这个项目默认使用的AHV cluster，选中该项目所能使用的网络 输入该项目的资源配额 选中刚才输入的AWS账户  点击 Save 按钮之后，选中页面中的 环境 那个标签\n在这个页面的连个标签页面中输入必要的信息，这里需要配置一个root账户信息，可以是用户名密码的，用在Calm登录虚拟机的时候。\n以上步骤的验收标准： 使用PC的默认用户名和密码成功登陆新安装的PC。 "
},
{
	"uri": "/00-getting-start/",
	"title": "基本配置",
	"tags": [],
	"description": "Nutanix Calm相关的基础配置",
	"content": " 环境需求 下载并安装最新版本的 Nutanix产品 。本站所使用的系统环境版本如下：\n NCC:3.50 Nutanix AHV: 20170830.58 Prism Central: 5.5  Nutanix提供免费的社区版软件，建议的版本组合如下：\n ce-2018.01.31-stable Nutanix CE ce-pc-deploy-2018.01.31 Nutanix PC   安装AHV群集 AHV群集产品安装说明和指导\n 配置和部署AD 最基本的配置\n "
},
{
	"uri": "/00-getting-start/installation/",
	"title": "安装AHV群集",
	"tags": [],
	"description": "AHV群集产品安装说明和指导",
	"content": "AHV 20170830.58 需要最小的版本，这个版本是Nutanix Calm内置于PC中的起始版本。 安装配置好AHV Cluster，配置好两个服务IP，如下图所示。\n如果以上的数据服务IP不设置，在将AHV群集注册到PC里的时候会报错，而无法完成注册。\n以上步骤的验收标准： 能使用AHV群集默认的初始化密码登陆PE。 "
},
{
	"uri": "/06-ce/01-install-ce-cluster/",
	"title": "环境准备",
	"tags": [],
	"description": "准备安装CE所需要的硬件和网络环境",
	"content": " 这个lab的目标：\n 选择兼容的硬件 准备好社区登录账户  硬件要求 Nutanix CE版本支持两种平台部署方式，一种是部署在物理服务器上，另外一种可以以虚拟机的形式部署。以下是使用Community Edition已经测试的过硬件配置建议。但是，与其他Community Edition用户一样，您可能会发现其他硬件和推荐的类型一样可以兼容，包含，但不仅限于以下硬件平台：\n   组件 推荐配置 说明     CPU Intel CPUs 支持 VT-x 至少配置4核; 2核给 Controller VM 专用   内存 至少16 GB，每个节点的CVM虚拟机，如果开启去重/压缩功能需要额外的内存开消。 如果想要使用AOS的去重和压缩功能，或者创建更多的虚拟机时，强烈建设配置32 GB    网卡 基于Intel的网卡 一些 Community Edition 用户使用Broadcom 网卡也有成功的.   HBA卡 Community Edition支持(AHCI) SATA, 或 LSI 控制器: * IT 模式 (Nutanix测试显示IT模式的性能优于IR模式) * IR 直通模式 * IR RAID-0模式    存储设备 每个节点的SSD/HDD数据最多为4块 有些Community Edition 用户也有超过4个设备的成功案例   冷数据层 不低于500 GB, 最大 18 TB (3 x 6 TB HDDs) 用于冷数据存储的HDD 或 SSD   热数据层 单个不低于200 GB SSD 将SSD(s)放在HDD之前(通常为0或1) 第一个槽位数字取决于制造商的标签。不支持基于NVMe的驱动器   引导分区 每节点一个8 GB 以上的设备. 可以是内置的，也可以是外置的 Nutanix已经成功测试过并使用了外部的USB设备和内部设备，比如SATA DOM 。建议使用USB 3.0 设备. 注意:如果你使用USB驱动器，在任何时候，不要删除USB驱动器。   固件 考虑为您将在Community Edition中使用的任何设备或硬件更新固件，以获得硬件供应商推荐的最新版本或建议版本。     硬件兼容型号举例    品牌 配置     Cisco Cisco UCS C220 M3 ; CPU: Intel Xeon E5-2609v2 2.5GHz ; RAM: 24GB DDR3 ; SSD: Cisco Enterprise Value SSD - 240 GB; HDD: Cisco - 500 GB - 2.5\u0026rdquo; SFF - SATA 6Gb/s - 7200 rpm ; NIC: Broadcom NetXtreme II 5709   Dell Dell PowerEdge R220; CPU: Intel Xeon E3-1220v3 3.1GHz; RAM: 32GB DDR3; SSD: Kingston SSDNow E50 - 480GB; HDD: 7.2k RPM SATA 3Gbps 2.5in - 1TB; NIC: On-Board LOM 1GBE (LAN on Motherboard)   HP HP ProLiant DL320e Gen8 v2； CPU: Intel Xeon E3-1220v3 3.1GHz；RAM: 32GB DDR3；SSD: Kingston SSDNow E50 - SSD - 240 GB；HDD: HP Midline HDD - 500 GB - SATA 6Gb/s - 7200 rpm；NIC: HP Ethernet 1Gb 2-port NC332i Adapter   SuperMicro SuperMicro SuperServer 1018D-73MTF；CPU: Intel Xeon E3-­1220v3 3.1GHz；RAM: 32GB DDR3；SSD: Seagate Pulsar.2 Enterprise SAS SSD - 200GB；HDD: Seagate Constellation.2 SATA 6Gb/s 7.2K RPM 64M - 500GB；NIC: Intel I210AT - Dual Gigabit Ethernet LAN    如果服务器不在以上的列表中，也可以查看以下链接：\nhttp://next.nutanix.com/t5/Discussion-Forum/Post-your-hardware-config/m-p/3249#U3249\n查找是否有兼容的型号。\n软件准备 国外下载链接：\nhttps://s3.amazonaws.com/ntnx-portal/ce/2017.07.21/ce-2017.07.20-stable.img.gz\n国内网盘下载链接：\nhttps://share.weiyun.com/d14f3d74680d553bcad0ab4b9b073614\n百度网盘链接:https://pan.baidu.com/s/1hsMpfla 密码: f7q4\n以上步骤的验收标准： 准备好可以安装CE的硬件和软件。 "
},
{
	"uri": "/06-ce/02-setup/",
	"title": " 安装部署",
	"tags": [],
	"description": "在服务器上安装CE",
	"content": " 这个lab的目标：\n 完成安装过程 启动和登录CE的Prism界面  物理环境部署 详细的说明参照官方文档：\nhttps://portal.nutanix.com/#/page/docs/details?targetId=Nutanix-Community-Edition-Getting-Started:Nutanix-Community-Edition-Getting-Started\n安装步骤如下所示：\n 使用工具将CE镜像刷到U盘 https://www.osforensics.com/tools/write-usb-images.html 使用U盘启动机器 使用install用户进行配置 使用cluster create命令创建集群 首次访问Prism，必须保持网络连接，必须提前注册my.nutanix.com的账号用于身份验证  使用U盘引导之后的安装开始界面如下：\n使用Install用户登录，不需要输入密码；输入install按回车。\n选择键盘布局，使用Tab键选择“Proceed” 这将消除磁盘上的任何现有数据。\n输入IP地址信息\nHost IP: 10.68.69.101 CVM IP: 10.68.69.102 Netmask: 255.255.255.0 Gateway: 10.68.69.1 Single controller DNS: 8.8.8.8  注意：安装需要连接Internet；只有一个设备时需要在Create single-mode cluster打勾选择\n完成安装之后，按回车，重启服务器。\n虚拟机环境部署 这种在虚拟化环境中部署CE属于实验目的，如果已经完成了以上的硬件服务器部署，请忽略下文，进入下一个章节。\n安装指南:\n 将CE镜像改为vmdk（如果是ESXi，使用vmkftools；如果是workstation，使用vmx文件） 使用install用户进行配置 使用cluster create命令创建集群 首次访问Prism，必须保持网络连接，必须提前注册my.nutanix.com的账号用于身份验证  以VMWare Workstation部署CE为例:\n解压ce-2017.07.20-stable.img.gz文件，你将得到一个名为“ce-2017.07.20-stable.img”的文件，将此文件改成“ce-flat.vmdk”。根据以下内容再创建名为ce.vmdk的描述文件。\nhttps://www.virtuallifestyle.nl/wp-content/uploads/2014/09/ce.txt\n新建一个虚拟机 设置虚拟机配置 添加磁盘 这是很关键的一步，对于VM的第一个磁盘，附加一个现有的SATA磁盘。选择上面创建的映像/磁盘描述符文件。 其它磁盘添加 除了第一个安装引导盘以外，再添加两块磁盘，第二块盘作为热数据层，第三块盘作为冷数据层。 启动虚拟机-开始安装 启动后，进行安装界面，安装方式跟之前物理环境中的过程一样。 访问Prism界面 输入CVM的IP地址，使用admin/admin登录Prism，并修改密码 按照提示使用my.nutanix.com的账号激活CE，此步骤需要访问Internet 激活成功后，开启你的HCI之旅吧！Enjoy it! 以上步骤的验收标准： 成功登陆Prism界面。 "
},
{
	"uri": "/04-nucalm-advance/02-owncloud-dvp/",
	"title": "Docker Datacenter使用DVP持久存储",
	"tags": [],
	"description": "安装和部署DDC，并使用DVP提供持久存储",
	"content": " Docker宣布Docker Datacenter（简称DDC）正式发布，这套可集成的端到端平台设计用于高效地将应用程序开发和管理工作由内部数据中心迁移至云环境下。\n在Docker Datacenter的帮助下，企业将能够立足于内部或者虚拟私有云环境实现容器即服务（简称CaaS）的部署工作。CaaS能够提供一整套IT管理及安全应用的内容与基础设施环境，开发人员则以此为基础通过自助服务模式实现应用程序的构建与部署。\nDocker Datacenter当中包含一系列领先的Docker开源项目、商用软件并同大量经过验证并受到支持配置相集成：\n Universal Control Plane (UCP) 1.0，嵌入Swarm以实现对Docker环境的管理与编排能力。 Trusted Registry (DTR) 1.4.3，用于实现Docker镜像管理、安全保护与协作。 Docker Engine 1.10对强大的container runtime提供商业支持。  本文介绍如何用Docker卷插件的方式，给Docker DDC的Swarm的群集挂载Nutanix存储。Nutanix Container Volume Plug-in 简称DVP，可以给容器提供数据持久化的功能。\n本文使用ownCloud网盘应用做功能测试。测试的过程如下，安装部署Docker Datacenter，配置好群集，在UCP的界面里调用DVP插件建持久的数据卷，建立ownCloud服务，部署和测试该服务。\n这个lab的目标：\n 在CentOS7的模板镜像虚拟机里安装配置Nutanix DVP 部署和配置DDC，包括UCP，DTR和worker节点 在UCP里配置DVP持久存储 在DTR里上传OwnCloud镜像 在DDC的Docker Swarm集群里部署OwnCloud 测试OwnCloud的功能 对OwnCloud的容器做摧毁性测试，验证数据的持久性  Docker服务的安装和配置 这一部分描述DVP的安装部署过程，需要连接互联网；安装调试完毕之后，将虚拟机的制作成新的镜像模板待用。这样就能是DDC里的所有节点不重复配置DVP。\n先在模板虚拟机里安装Docker服务，Docker服务的安装方法见Docker的官方文档。\nDocker安装的参考命令如下：\n$ sudo yum install -y yum-utils \\ device-mapper-persistent-data \\ lvm2 $ sudo yum-config-manager \\ --add-repo \\ https://download.docker.com/linux/centos/docker-ce.repo $ sudo yum install docker-ce $ sudo systemctl start docker $ sudo systemctl enable docker  本文使用的是Docker社区文档稳定版 17.03.1-ce ；本文使用的OS是CentOS 7.3。所Docker安装的版本如下：\n[root@centos7-temp]# docker version Client: Version: 17.03.1-ce API version: 1.27 Go version: go1.7.5 Git commit: c6d412e Built: Mon Mar 27 17:05:44 2017 OS/Arch: linux/amd64 Server: Version: 17.03.1-ce API version: 1.27 (minimum version 1.12) Go version: go1.7.5 Git commit: c6d412e Built: Mon Mar 27 17:05:44 2017 OS/Arch: linux/amd64 Experimental: false [root@centos7-temp]# rpm -qa|grep docker docker-ce-17.03.1.ce-1.el7.centos.x86_64 docker-ce-selinux-17.03.1.ce-1.el7.centos.noarch  本文使用的Docker 安装yum源如下：\n[root@centos7-temp]# cat /etc/yum.repos.d/docker-ce.repo [docker-ce-stable] name=Docker CE Stable - $basearch baseurl=https://download.docker.com/linux/centos/7/$basearch/stable enabled=1 gpgcheck=1 gpgkey=https://download.docker.com/linux/centos/gpg [docker-ce-stable-debuginfo] name=Docker CE Stable - Debuginfo $basearch baseurl=https://download.docker.com/linux/centos/7/debug-$basearch/stable enabled=0 gpgcheck=1 gpgkey=https://download.docker.com/linux/centos/gpg [docker-ce-stable-source] name=Docker CE Stable - Sources baseurl=https://download.docker.com/linux/centos/7/source/stable enabled=0 gpgcheck=1 gpgkey=https://download.docker.com/linux/centos/gpg [docker-ce-edge] name=Docker CE Edge - $basearch baseurl=https://download.docker.com/linux/centos/7/$basearch/edge enabled=0 gpgcheck=1 gpgkey=https://download.docker.com/linux/centos/gpg [docker-ce-edge-debuginfo] name=Docker CE Edge - Debuginfo $basearch baseurl=https://download.docker.com/linux/centos/7/debug-$basearch/edge enabled=0 gpgcheck=1 gpgkey=https://download.docker.com/linux/centos/gpg [docker-ce-edge-source] name=Docker CE Edge - Sources baseurl=https://download.docker.com/linux/centos/7/source/edge enabled=0 gpgcheck=1 gpgkey=https://download.docker.com/linux/centos/gpg [docker-ce-test] name=Docker CE Test - $basearch baseurl=https://download.docker.com/linux/centos/7/$basearch/test enabled=0 gpgcheck=1 gpgkey=https://download.docker.com/linux/centos/gpg [docker-ce-test-debuginfo] name=Docker CE Test - Debuginfo $basearch baseurl=https://download.docker.com/linux/centos/7/debug-$basearch/test enabled=0 gpgcheck=1 gpgkey=https://download.docker.com/linux/centos/gpg [docker-ce-test-source] name=Docker CE Test - Sources baseurl=https://download.docker.com/linux/centos/7/source/test enabled=0 gpgcheck=1 gpgkey=https://download.docker.com/linux/centos/gpg  本机所使用的所有安装源如下：\n[root@centos7-temp]# yum repolist Loaded plugins: fastestmirror Loading mirror speeds from cached hostfile * base: mirrors.aliyun.com * epel: mirrors.aliyun.com * extras: mirrors.aliyun.com * updates: mirrors.aliyun.com repo id repo name status base/7/x86_64 CentOS-7 - Base - mirrors.aliyun.com 9,363 docker-ce-stable/x86_64 Docker CE Stable - x86_64 4 epel/x86_64 Extra Packages for Enterprise Linux 7 - x86_64 11,808 extras/7/x86_64 CentOS-7 - Extras - mirrors.aliyun.com 381 updates/7/x86_64 CentOS-7 - Updates - mirrors.aliyun.com 1,859 repolist: 23,415  安装docker引擎，并启动服务，并校验服务状态。安装过程参考如下：\n[root@centos7-temp]# yum install -y docker-ce [root@centos7-temp]# systemctl enable docker [root@centos7-temp]# systemctl start docker [root@centos7-temp]# systemctl status docker ● docker.service - Docker Application Container Engine Loaded: loaded (/usr/lib/systemd/system/docker.service; enabled; vendor preset: disabled) Active: active (running) since Tue 2017-06-20 20:30:49 CST; 19min ago Docs: https://docs.docker.com Main PID: 875 (dockerd) CGroup: /system.slice/docker.service ├─ 875 /usr/bin/dockerd ├─ 942 docker-containerd -l unix:///var/run/docker/libcontainerd/docker-containerd.sock --metrics-in... ├─2008 docker-containerd-shim 0ca2346b6126de702fb4dda5f807c0a69a402eb643f15c142730277d0eb7bbcb /var/... └─0ca2346b6126de702fb4dda5f807c0a69a402eb643f15c142730277d0eb7bbcb └─2038 /usr/bin/python /code/main.py --prism-ip 10.68.69.22 --dataservices-ip 10.68.69.23 --prism-...  到目前为止，Docker安装配置完成。\nNutanix DVP (Docker Volume Plug-in)安装和配置 下面开始安装DVP，安装和配置过程参考页面。\nhttps://store.docker.com/plugins/nutanix-dvp-docker-volume-plug-in\n下面是给操作系统安装iscsi initiator服务的参考步骤：\nyum install -y iscsi-initiator-utils systemd-tmpfiles --create systemctl start iscsid systemctl enable iscsid systemctl status iscsid ● iscsid.service - Open-iSCSI Loaded: loaded (/usr/lib/systemd/system/iscsid.service; enabled; vendor preset: disabled) Active: active (running) since Tue 2017-06-20 20:30:46 CST; 24min ago Docs: man:iscsid(8) man:iscsiadm(8) Main PID: 888 (iscsid) CGroup: /system.slice/iscsid.service ├─882 /usr/sbin/iscsid └─888 /usr/sbin/iscsid Jun 20 20:30:46 centos7-temp.zenlab.local systemd[1]: Starting Open-iSCSI... Jun 20 20:30:46 centos7-temp.zenlab.local iscsid[878]: iSCSI logger with pid=882 started! Jun 20 20:30:46 centos7-temp.zenlab.local systemd[1]: Failed to read PID from file /var/run/iscsid.pid: Inva...ent Jun 20 20:30:46 centos7-temp.zenlab.local systemd[1]: Started Open-iSCSI. Jun 20 20:30:47 centos7-temp.zenlab.local iscsid[882]: iSCSI daemon with pid=888 started! Hint: Some lines were ellipsized, use -l to show in full.   解释一下DVP的工作原理是，它是让Docker主机通过iSCSI协议连接Nutanix的存储服务。DVP插件的配置里包含了连接存储服务和存储容器（这个容器是Nutanix的存储术语，非Docker说的容器）的相关信息。这样Docker主机上用该卷插件建立的数据卷都会指向Nutanix后台的存储容器中；数据通过iSCSI协议连接Nutanix存储服务的时候，就可以利用到Nutanix群集提供的负载均衡能力；当数据块写入Nutanix存储池的过程中和之后，就可以利用到到Nutanix存储容器所具备的其它重要特性：数据块2~3副本的高可靠性、冷热数据分成、压缩、去重、纠删码等；而且存储空间对于容器或者Docker Swarm里的服务都是透明和无限容量的。\n 现在做一些安装DVP的准备工作，向Nutanix系统管理员要求并记录下面的信息：\n 获得Prism的界面访问 IP 获得Nutanix群集数据服务的IP，这个IP是群集上的虚拟服务IP 获得群集的用户名和密码 新建一个测试存储容器，获得容器名  以上信息会使用在DVP的安装命令中，DVP的离线安装方法：下载DVP插件镜像，保存成文件，ssh上传到模板虚拟机，用docker load命令加载安装。\n参考下面的DVP安装命令：\ndocker plugin install ntnx/nutanix_volume_plugin PRISM_IP=\u0026quot;10.68.69.22\u0026quot; DATASERVICES_IP=\u0026quot;10.68.69.23\u0026quot; PRISM_PASSWORD=\u0026quot;nutanix/4u\u0026quot; PRISM_USERNAME=\u0026quot;admin\u0026quot; DEFAULT_CONTAINER=\u0026quot;ddc-sc1\u0026quot; --alias nutanix  以上的命令执行结果如下：\n[root@centos7-temp]# docker plugin install ntnx/nutanix_volume_plugin PRISM_IP=\u0026quot;10.68.69.22\u0026quot; DATASERVICES_IP=\u0026quot;10.68.69.23\u0026quot; PRISM_PASSWORD=\u0026quot;nutanix/4u\u0026quot; PRISM_USERNAME=\u0026quot;admin\u0026quot; DEFAULT_CONTAINER=\u0026quot;ddc-sc1\u0026quot; --alias nutanix Plugin \u0026quot;ntnx/nutanix_volume_plugin\u0026quot; is requesting the following privileges: - network: [host] - mount: [/dev] - mount: [/lib/modules] - mount: [/etc/iscsi] - mount: [/var/lock/iscsi] - mount: [/proc] - allow-all-devices: [true] - capabilities: [CAP_SYS_ADMIN CAP_SYS_PTRACE CAP_IPC_LOCK CAP_IPC_OWNER CAP_NET_ADMIN CAP_MKNOD CAP_SYS_MODULE] Do you grant the above permissions? [y/N] y （输入y，按回车） latest: Pulling from ntnx/nutanix_volume_plugin be892c8cb64d: Download complete Digest: sha256:5a3730ffae077eb6ddc0c125620283d56852528b686cbe42f2f58696eab82c0d Status: Downloaded newer image for ntnx/nutanix_volume_plugin:latest Installed plugin ntnx/nutanix_volume_plugin  确认VDP安装结果，这个插件应该是最新版、启动的状态，如下：\n[root@centos7-temp]# docker plugin ls ID NAME DESCRIPTION ENABLED f0e38fbc11b3 nutanix:latest Nutanix volume plugin for docker true  关于 docker plugin 的相关命令参考文档，见docker官网。\n执行下面的测试，确认DVP工作正常。\n[root@centos7-temp]# docker volume create testvol -d nutanix:latest testvol [root@centos7-temp]# docker volume ls DRIVER VOLUME NAME nutanix:latest testvol [root@centos7-temp]#  回到Nutanix的Prisum界面（主要的群集管理图形化界面）中查看Storage \u0026ndash;\u0026gt; table \u0026ndash;\u0026gt; Volume Group，应该能看到这个命令所创建的名为testvol的数据卷。如下图所示：\n在命令行删除这个测试的卷。\n[root@centos7-temp]# docker volume rm testvol testvol [root@centos7-temp]# docker volume ls DRIVER VOLUME NAME [root@centos7-temp]#  在回到Prisum界面中查看刚才看到的那个卷应该就消失了。到此为止所有节点的DVP部署配置工作就完毕了，并且确认docker服务和DVP功能都很正常。用 sys-unconfig 命令关机，把这个虚拟机在Prisum里面做一个快照备用，也可以在Nutanix的nucli命令行里面把它做成一个基础镜像。\n安装Docker For DaterCenter 我们已经理解和熟悉了DVP的基本操作，配置和部署，下面开始安装Docker Datacenter；Docker Datacenter的架构图如下所示： 本文安装的架构是：\n 一个 UCP manager 节点 一个 DTR 节点 两个 worker node 节点  在Nutanix的Prisum中用刚才制作的那个快照或者镜像模板，克隆/新建4个虚拟机。虚拟机的参考配置如下：\n 2 vCPU 4GB RAM 50GB Disk  安装UCP（Docker Universal Control Plane）节点 在Nutanix的Prisum中从刚才新建的四个虚拟机中选择一个，Power on开机；ssh登录到操作系统内之后，设定主机名和IP地址。\n安装配置参考文档：https://docs.docker.com/datacenter/ucp/2.1/guides/admin/install/install-offline/#download-the-offline-package\n注意事项，提前下载好安装包，这个tar包里面包含了UCP需要的所有镜像，可以一次性导入到UCP的节点上。\n下面是参考命令，在使用本文档时，请下载并安装最新版的Docker for Datacenter产品包。\nwget https://packages.docker.com/caas/ucp_images_2.1.4.tar.gz -O docker-datacenter.tar.gz docker load \u0026lt; docker-datacenter.tar.gz  载入完毕后，可以看到如下镜像。\n[root@ucp-master ~]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE docker/ucp-metrics 2.1.4 e3e24ef156bd 3 weeks ago 92.2 MB docker/ucp-swarm 2.1.4 d8b51d6801e5 3 weeks ago 21 MB docker/ucp-hrm 2.1.4 38a19323327d 3 weeks ago 14.8 MB docker/ucp-etcd 2.1.4 9aa382502e19 3 weeks ago 38.5 MB docker/ucp-controller 2.1.4 5a852aa3039e 3 weeks ago 28 MB docker/ucp-dsinfo 2.1.4 66ee9368796a 3 weeks ago 159 MB docker/ucp 2.1.4 7a28dbfc44e4 3 weeks ago 19.1 MB docker/ucp latest 7a28dbfc44e4 3 weeks ago 19.1 MB docker/ucp-cfssl 2.1.4 acdc1f147711 3 weeks ago 15.1 MB docker/ucp-compose 2.1.4 25775e989077 3 weeks ago 32.9 MB docker/ucp-auth-store 2.1.4 f27ad13dee6c 3 weeks ago 58.7 MB docker/ucp-agent 2.1.4 d716a096c331 3 weeks ago 22.5 MB docker/ucp-auth 2.1.4 1f4739cd3c08 3 weeks ago 25.1 MB [root@ucp-master ~]#  安装UCP的命令参考如下：\ndocker run --rm -it --name ucp \\ -v /var/run/docker.sock:/var/run/docker.sock \\ docker/ucp:2.1.4 install \\ --host-address 10.68.69.12 \\ --interactive  以上命令中10.68.69.12是UCP主机的ip地址，建议UCP使用固定IP。以上命令完毕后用浏览器访问这个IP。\n参考以下文档，完成UCP的安装步骤，其中需要到Docker网站获得30天的试用版许可证文件。\nhttps://docs.docker.com/datacenter/ucp/2.1/guides/admin/install/\n能够正常登陆访问UCP之后，在首页下方点击 【Add Node】按钮，获得加其它节点到群集里的命令，参考命令如下：\ndocker swarm join \\ --token SWMTKN-1-1310ah7gzj9e7bk6a5yobo2qyiwf93ybrd29flkved1zqydd6i-7pir0884sag5pjofwzjq5o1um \\ 10.68.69.12:2377  把以上命令记录在写字板中备用。\n加3个节点到群集里 把剩下的三个虚拟机开机，进入操作系统后设定主机名和IP。其中的一个安装DTR（Docker镜像仓库）的节点建议使用固定IP。\n在每个操作系统里面用docker命令确认DVP是否正常。\n docker plugin ls docker volume ls systemctl status iscsid  下面就可以把上一步所记录命令在命令行里面执行以下，完毕之后回到UCP的界面中查看是否它们已经添加成功。如下图所示：\n安装DTR-Docker镜像仓库 在UCP首页的下方，找到并点击 【Install DTR】的按钮，取得安装命令（记得从清单中选择固定IP地址的DTR主机）；在登录DTR主机的控制台里面输入这个命令，命令如下：\ndocker run -it --rm \\ docker/dtr:2.2.5 install \\ --ucp-node 10.68.69.12 \\ --ucp-insecure-tls  DTR节点没有离线安装的整合包，它需要联网下载很多相关镜像，如果网络速度不是很快的话，下载和安装的过程需要至少半个小时，过程中还需要输入UCP的管理员，用户名和密码。\n参考文档如： https://docs.docker.com/datacenter/dtr/2.2/guides/admin/install/#step-3-install-dtr\nDTR正常工作了以后，登录建立一个名为owncloud的镜像库，点击【New Rrepository】输入owncloud。 在一个节点上下载owncloud镜像，添加新的tag，上传到这个镜像到镜像库里备用。参考命令如下：\ndocker login dtr.zenlab.local docker pull owncloud docker tag owncloud:latest dtr.zenlab.local/admin/owncloud:latest docker push dtr.zenlab.local/admin/owncloud:latest  注意：如果你的环境中没有DNS，就把dtr.zenlab.local换成DTR的IP地址。\n以上这个步骤主要是方便以后，反复使用和测试这个镜像的可能性，如果所有的节点都有高速的互联网链接，可以忽略以上步骤。\n如果你所在的实验环境是没有互联网连接的，你需要将OwnCloud的镜像下载并保存成tar包，然后在传到DTR里，这样群集里的所有节点就可以在DTR里就近获得这个镜像，并启动OwnCloud容器了\n在Docker Datacenter群集中使用DVP 这里使用UCP的图形化界面，在一个所有节点都配置和部署了VDP的群集上，给群集挂载外部Nutanix的数据卷。挂载的数据卷是给OwnCloud做持久存储用的。\n登录UCP主页，点击Resource，点击Volumes，点击 【Create Volume】，输入相关参数，如下图所示。图中的sizeMb=500000这个参数是制定VolumeGroup的大小，不设定这个参数的话，默认是10GB。 在到Nutanix的Prism里面查看这个Volume Group是否存在。应该如下图所示：\n部署OwnCloud网盘服务 登录UCP主页，点击 Service ， 点击 【Create a Service】按钮；开始建立这个服务。输入服务名，镜像名；点击 【Next】按钮。\n点击 【Next】按钮。进入 Resource页面，这里需要配置端口和数据卷。 最后点击【Deploy Now】按钮。 部署完毕之后，显示这个服务的状态为正常。 点击这个服务，到这个页面的最下方，找到右下角的发布端口的链接，点击后，就可以看到ownCloud的初始化配置页面了。 输入管理员的用户名和密码，进入之后，上传一些图片，测试一下功能是否正常。\n尝试一些Docker Datacenter的高级功能，如服务的高可用性；同时Nutanix的DVP在底层保障了数据的持久性和完全性。测试步骤如下：\n 找到运行owncloud的容器，删除这个容器 在服务页面查看owncloud服务的状态变化 等ownCloud的状态恢复正常之后 再次登录ownCloud页面 查看和确认刚才上传的文件是否还在  总结 Nutanix是一种融合和了计算、存储和虚拟化（内置KVM）的超融合平台。Nutanix DVP (Docker Volume Plug-in)可以让平台里的容器用上持久化存储服务。DVP不仅可以给单独虚拟机里的容器提供持久卷服务，还能给类似于Docker Swarm的其它容器编排平台提供持久化数据服务功能。\n以上步骤的验收标准： 可以在Nutanix上部署和运行Docker Datacenter，可以给Docker Datacenter的Swarm群集使用DVP持久存储，OwnCloud的网盘服务能高可用的存在和运行。 "
},
{
	"uri": "/03-nucalm-middle/02-3layer/",
	"title": "三层LAMP应用蓝图",
	"tags": [],
	"description": "基于LAMP技术堆栈的典型三层应用",
	"content": "本Lab的目标： * 使用一个下载的别人开发的蓝图 * 导入在自己的项目中 * 在本地项目的蓝图编辑器里修改成一个可以正常运行的蓝图 * 使用当前项目的配额测试和部署这个蓝图的应用 * 使用和测试蓝图中所定义的自动化运维流程 * 修改和增加自定义的应用服务自动化维护场景（可选）\n蓝图的下载地址：http://lab.digitalformula.net/calm-lab-3.0/blueprints/2017.12.06.LAMP.RC6.json.zip\n下载后解压缩得到蓝图的 json 文件。\n在App页面中点击左侧的第二个按钮，进入蓝图管理，点击 Upload Blueprint 按钮，通过上传的方式新建一个蓝图。点击后选择刚才下载的json蓝图文件。\n输入这个蓝图在本地的名称和部署的项目。点击 上传 按钮。 上传之后进入该蓝图的编辑模式，可以点击图中的红色感叹号，了解当前蓝图里必须修改的配置点。然后逐一检查和确认每一项配置，保证所有配置和当前的项目和资源池匹配。\n点击 Credentials 按钮，将密码更新为上述步骤中创建的模板机的root口令， Credentials name最好保持不变。点击空白处和密码查看的眼睛图标，确认密码应保存住了，点击 back 按钮。\n依次点击左下角Service清单中的三项服务，修改每项服务中的详细配置，如下图所示。 确保使用正确的登录密码信息。 点击保存按钮，确认整个蓝图的配置信息都是正确的，点击 Lunch 按钮部署这个蓝图。 输入这次蓝图部署的名称，点击Create按钮，创建这个部署。 在应用部署界面中观察 Create 工作流的执行状态。 在虚拟机控制台里观察虚拟机创建的状态和结果。 部署完毕之后可以范围 负载均衡 服务状态查看地址： http://10.21.11.55:8080/stats\n如果右下方的两个服务的状态都是UP的话，这表明整套服务部署成功了。然后访问 http://haproxy_vm_ip/ 浏览应用服务页面。\n以上步骤的验收标准： 可以登录用户蓝图生成的vm，能看到三层应用的Web界面。 "
},
{
	"uri": "/02-nucalm-basic/02-deploy-bp/",
	"title": "导入Nutanix Calm商店里的蓝图",
	"tags": [],
	"description": "Calm里应用商店的初始化配置",
	"content": "Nutanix Calm商店是在公网上的，点击左侧的图标，如果当前的这个Cluster可以上互联网就可以看到如图所示的应用清单，这些是Nutanix已经测试打包好的应用蓝图。\n选择若干种应用蓝图，选中那些项目需要使用这个蓝图，点击 Apply 之后，点击 Publish按钮，这样这个蓝图就下载并且导入到了本地的Calm应用商店里。\n下图是导入完之后的结果，点击左侧最上面的按钮后，可以看到本地应用商店的状态。 以上步骤的验收标准： 本地的应用商店里获取到了可以部署的应用蓝图，这些蓝图是成功地从互联网上下载到本地。 "
},
{
	"uri": "/00-getting-start/configuration/",
	"title": "配置和部署AD",
	"tags": [],
	"description": "最基本的配置",
	"content": "AD或者LDAP服务器是配置PC的必备的服务，在使用PC提供的自助服务门户的时候，需要使用AD作为用户认证的来源。\n工作内容包括：\n 建立SSP（自助服务）所需要的组和用户 建立管理员组：ssp_admin 建立用户组： ssp_user 在这两个组里建立若干个测试用户，用于测试SSP中的不同角色。  以上工作内容贯彻了下面文档的所有步骤，作为一次WorkShop中的完整的配置。如果你使用已有的AD服务器，请参考以上配置，并不需要建立以上的用户和组。\n 建立的组如下图所示：\n用户和组建立完成之后的结果如下图所示：\n以上步骤的验收标准： 记录新建/已有测试账户的用户名和密码，每一个账户都可以成功地登陆AD域。 "
},
{
	"uri": "/06-ce/03-basic-ops/",
	"title": "常用功能操作",
	"tags": [],
	"description": "CE的最基本的操作和使用介绍",
	"content": " 这个lab的目标：\n 常见功能 Prism界面的基本使用  显示配置集群管理地址 点击左上角集群名称，可以显示集群详细信息以及配置集群管理地址： 更新用户信息 用于更新当前用户的联系方式，包括电子邮件地址 更改用户登录口令 REST API浏览器 查询所有Rest API接口 下载nCLI 下载命令行工具包nCLI，用于在windows或者其他支持Java平台的系统上可以通过命令行远程管理集群 解压之后在命令行中运行，即可连接到远程集群，执行管理命令，如：\n查询集群版本： 获取主机列表： 下载并安装windows Cmdlets工具包 下载Windows Cmdlets工具包，可以提供Windows管理员用熟悉的Powershell进行集群管理 技术支持中心网站 当需要寻求技术支持时，可以直接从Prism界面中打开技术支持中心网站，并登陆即可 打开文档中心网站 点击帮助时，可以打开在线的文档页面，查找所有Nutanix最新文档资料 集群健康检查功能演示 点击Health Tutorial即可通过动画方式详细了解Nutanix Health Check功能如何使用 打开Nutanix社区网站 点击Nutanix Next Community可以打开Nutanix社区网站寻求社区的协助 添加AD域用户登录验证 添加AD域名和验证的IP地址端口：ldap://10.91.233.78:389，可以使用AD进行用户验证 角色映射 可以将域账号中的角色映射为Nutanix的管理员用户或者普通用户 创建本地用户 可以创建其他管理员用户或者非管理员用户 使用域账号登陆 配置邮件服务器地址 配置邮件服务器地址用于发送告警邮件 配置告警邮件 配置发送告警邮件给管理员或者Nutanix Support 告警策略配置 针对不同告警，可以配置响应的告警策略通知管理员，避免发生告警风暴 网络文件系统白名单 允许特定网段的IP访问Nutanix存储 软件升级 简单的一键升级功能，可以同时支持升级NOS、Hypervisor、NCC和Firmware，并且实现无人值守升级过程。 字符界面也可以查看升级过程 自定义欢迎信息或者免责声明等 输入个性化欢迎信息或者免责声明，当用户打开网页即可看到该信息。 配置Nutanix的DNS服务器地址 输入DNS服务器地址 配置NTP服务器 输入NTP服务器地址 小结  Nutanix的Prism作为统一的管理接口，不仅可以管理服务器、存储等基础架构，并且可以实时监控Nutanix平台上所有虚拟机状态，用户可以通过一个界面完成日常监控、维护、快速故障定位和诊断、在线升级vSphere和NOS、告警管理、用户管理等日常操作 Nutanix更提供命令行接口和预定义Windows Cmdlets脚本，供高级用户开发自动化脚本以实现自动化运维操作 Nutanix提供的REST API接口可以方便的与其他监控系统进行整合，简化运维人员日常运维成本。Nutanix也提供SCOM整合的监控管理工具包，便于用户将与现有Microsoft SCOM监控平台进行对接  "
},
{
	"uri": "/03-nucalm-middle/03-ec2-demo/",
	"title": "模拟AWS EC2蓝图",
	"tags": [],
	"description": "创建一个模拟AWS EC2服务的蓝图",
	"content": " 这个lab的目标：\n 蓝图使用上面的CentOS7的模板镜像 创建模仿AWS EC2虚拟机服务的蓝图 建立两种规格的虚拟机 可以设置虚拟机的其它各种参数  参考蓝图 可以在GitHub下载本文示例蓝图文件，网址：https://github.com/Nutanix-lab/calm。 下面是这个蓝图的关键配置讲解。\n应用基础配置 - Application Profile 在变量清单这里增加一个vm_hostname变量，设置初始值为vmhostname\nEC2服务配置 - 规格参数  配置VM Name，设置两个变量组成的虚拟机名称，用于在Prism里查询 配置 martin-centos-t1 为初始化的默认镜像，点亮右侧的小人，这样就可以使蓝图的使用者在运行这个蓝图的时候，选择这个参数的值，而不是预想定死的   添加一块数据盘，初始8GB，用户可变更 配置默认网络为vlan128，用户可变更（右侧小蓝人已经被点亮）  EC2服务配置 - 软件包安装  基于martin-centos-t1模板的预装软件包，如果有其它扩展安装和配置的可以把命令写在这里 这里使用了一个修改虚拟机主机名的操作  EC2服务配置 - 虚拟机副本数量  默认配置为1，用户运行时可变  测试EC2蓝图 在蓝图编辑器里点击右上角的Launch按钮。\n 配置这次部署的应用名称 修改vm_hostname的名称为 xyz-bank 点击VM Configuration下面的EC2，在里面可以看到所有运行时可以变更的参数，找到参数：number of replicas ；修改默认的1位3； 点击右下角的 Create 按钮  观察测试结果 进入Application，点击右侧第三个图标；点击Manager，点击Create的右侧的眼睛的按钮。查看整个部署的过程。点击 Services Tab；观察已经创建的三个虚拟机的IP地址。\n进入Explore-\u0026gt; VM 在搜索栏输入 xyz 按回车，应该能看到以下三个虚拟机；\n点击其中的一个vm\n点击这个vm上面的console\n在控制台中登入操作系统，运行 hostname 命令，确认是否是预想的主机名。\n删除这次部署 回到Nutanix Calm界面，点击右侧的第三个按钮。选中目标要删除的应用部署，选中菜单中的 Delete 命令。\n以上步骤的验收标准： 以上新建的三个虚拟机被删除，无法搜索出来。 "
},
{
	"uri": "/02-nucalm-basic/03-config-cat/",
	"title": "配置服务目录",
	"tags": [],
	"description": "在自助服务的门户里，可以选择ISO和磁盘镜像",
	"content": "服务目录是为SSP用户提供的最基础的资源服务，下面是配置SSP用户可以访问到的ISO和磁盘镜像模板的方法。\n以SSP管理员用户身份登录。\n点击左侧的 Images ， 在镜像管理页面里，选择 Add Images 按钮，上传可以用于SSP的ISO和Disk镜像。选中其中需要通过服务目录展示给最终用户的镜像。 配置镜像在服务目录中看到的名字和描述。\n点击右侧的 Catalog Items 参考最后发布的效果。\n退出Admin用户，换SSP用户登录。下面是Developer用户角色能看到的内容。\n以上步骤的验收标准： 服务目录里的镜像可以供给SSP用户创建虚拟机。 "
},
{
	"uri": "/03-nucalm-middle/04-lamp-bp/",
	"title": "LAMP技术堆栈蓝图",
	"tags": [],
	"description": "创建带有负载均衡能力的LAMP(/images/服务的蓝图",
	"content": " 这个lab的目标：\n 蓝图使用上面的CentOS7的模板镜像 创建数据库、app、LB服务 设置服务的各种安装包 设置用于应用部署的变量参数  参考蓝图 可以在GitHub下载本文示例蓝图文件，网址：https://github.com/Nutanix-lab/calm，蓝图文件名：LAMP_colo.json。 下面是这个蓝图的关键配置讲解。\n下载上传本蓝图的步骤省略，参考本章前两篇文章。\n蓝图中的重点配置 设置量变量参数，用于参数化这个LAMP模板 * 配置MySQL数据库密码 * 变量 DEMO_COMP 用于初始化 Apache的默认首页的内容，扩展开去，你也可以设置为在Apache/Php服务器上部署的应用的代码的参数，如：下载网址等，这样就可以让这个蓝图自动化的部署目标运行的应用代码。\n 数据库服务器的基础模板选择 martin-centos-t1 这里设定的是不可变 其它的虚拟机规格参数配置如EC2 Demo蓝图，参考上文。   这段脚本是数据库服务的数据安装命令 使用了应用级别的变量初始化MySQL数据库root口令   这段脚本是Apache服务的安装命令 使用了应用级别的变量初始化网站首页的内容，本例中及用于演示的目的 真实场景中，可以是一段动态的拉取应用代码吧的脚本，参数可以是应用的名称、版本和位置等。   Apache服务器在LB负载均衡器的后面，默认两个副本 副本数在部署的时候可选  蓝图的代码 数据库 #!/bin/bash set -ex # -*- Mysql installation #sudo yum install -y \u0026quot;http://repo.mysql.com/mysql-community-release-el7.rpm\u0026quot; sudo yum update -y sudo yum install -y mariadb-server mariadb sudo systemctl start mariadb sudo systemctl enable mariadb # -*- Mysql secure installation mysql -u root\u0026lt;\u0026lt;-EOF UPDATE mysql.user SET Password=PASSWORD('@@{MYSQL_PASSWORD}@@') WHERE User='root'; DELETE FROM mysql.user WHERE User='root' AND Host NOT IN ('localhost', '127.0.0.1', '::1'); DELETE FROM mysql.user WHERE User=''; DELETE FROM mysql.db WHERE Db='test' OR Db='test\\_%'; FLUSH PRIVILEGES; EOF  应用服务器 #!/bin/bash set -ex # -*- Install httpd and php sudo yum update -y sudo yum install -y httpd php php-mysql echo \u0026quot;\u0026lt;IfModule mod_dir.c\u0026gt; DirectoryIndex index.php index.html index.cgi index.pl index.php index.xhtml index.htm \u0026lt;/IfModule\u0026gt;\u0026quot; | sudo tee /etc/httpd/conf.modules.d/dir.conf echo \u0026quot;\u0026lt;?php phpinfo(); ?\u0026gt;\u0026quot; | sudo tee /var/www/html/info.php echo \u0026quot;\u0026lt;h1\u0026gt; @@{DEMO_COMP}@@ \u0026lt;/h1\u0026gt; \u0026lt;?php echo gethostname(); ?\u0026gt;\u0026quot; | sudo tee /var/www/html/index.html sudo systemctl restart httpd sudo systemctl enable httpd  负载均衡 #!/bin/bash set -ex port=80 sudo yum update -y sudo yum install -y haproxy echo \u0026quot;global log 127.0.0.1 local0 log 127.0.0.1 local1 notice maxconn 4096 quiet user haproxy group haproxy defaults log global mode http retries 3 timeout client 50s timeout connect 5s timeout server 50s option dontlognull option httplog option redispatch balance roundrobin # Set up application listeners here. listen stats 0.0.0.0:8080 mode http log global stats enable stats hide-version stats refresh 30s stats show-node stats uri /stats listen admin bind 127.0.0.1:22002 mode http stats uri / frontend http maxconn 2000 bind 0.0.0.0:80 default_backend servers-http backend servers-http\u0026quot; | sudo tee /etc/haproxy/haproxy.cfg sudo sed -i 's/server host-/#server host-/g' /etc/haproxy/haproxy.cfg hosts=$(echo \u0026quot;@@{APACHE_PHP.address}@@\u0026quot; | sed 's/^,//' | sed 's/,$//' | tr \u0026quot;,\u0026quot; \u0026quot;\\n\u0026quot;) for host in $hosts do echo \u0026quot; server host-${host} ${host}:${port} weight 1 maxconn 100 check\u0026quot; | sudo tee -a /etc/haproxy/haproxy.cfg done sudo systemctl daemon-reload sudo systemctl enable haproxy sudo systemctl restart haproxy  测试和验证 如前文所述Launch这个蓝图，在Service菜单中找到负载均衡HAPROXY服务，点击该服务，找到它的IP地址。\n在Chrome浏览器里转到这个ip地址的访问。\n 这个页面显示的是启动应用是设置的变量 DEMO_COMP  以上步骤的验收标准： 通负载均衡进入的Apache服务器的默认网页上显示的是启动自定义的字段。 "
},
{
	"uri": "/02-nucalm-basic/04-create-template/",
	"title": "创建虚拟机模板",
	"tags": [],
	"description": "创建自定义的虚拟机模板",
	"content": " 通过ISO光盘安装虚拟机 这个步骤是为测试Calm的蓝图做准备，安装一个CentOS 7 的虚拟机，并且把它转化成模板镜像。\n点击 Create VM 按钮，创建一个虚拟机。\n点击 Next 下面输入磁盘信息和CPU内存的配置信息。点 Save 按钮。 进入新创建虚拟机的控制台。\n在安装完的模板虚拟机里运行一下命令，方便后面的蓝图测试，把这些包装好，后面能更快速一些。\nyum install httpd mariadb-server mariadb php php-mysql php-gd nano wget bind-utils net-tools reboot  编辑 /etc/ssh/sshd_config 文件， 取消这一行的注释： PasswordAuthentication yes\n再次登录以后用 sys-unconfig 关机。 以下文档内容参考了 http://lab.digitalformula.net/；\n将测虚拟机磁盘转成模板镜像 ssh登录到AHV Cluster中的一个CVM。登录后执行acli命令，然后输入一下命令\n\u0026lt;acropolis\u0026gt; vm.get centos-tmp include_vmdisk_paths=1 centos-tmp { config { allow_live_migrate: True disk_list { addr { bus: \u0026quot;ide\u0026quot; index: 0 } cdrom: True device_uuid: \u0026quot;1fd10d29-0ac1-425d-99cc-ecffd6593fb2\u0026quot; empty: True } disk_list { addr { bus: \u0026quot;scsi\u0026quot; index: 0 } container_id: 418 container_uuid: \u0026quot;08e01b3e-1bfa-45e0-ba11-5155380e0b1f\u0026quot; device_uuid: \u0026quot;afe6d35e-97a1-4f16-976a-87fd4c702c2e\u0026quot; vmdisk_nfs_path: \u0026quot;/SelfServiceContainer/.acropolis/vmdisk/35ae574b-725f-4ea8-977c-b5c9c42857ca\u0026quot; vmdisk_size: 8589934592 vmdisk_uuid: \u0026quot;35ae574b-725f-4ea8-977c-b5c9c42857ca\u0026quot; } hwclock_timezone: \u0026quot;UTC\u0026quot; machine_type: \u0026quot;pc\u0026quot; max_hotplug_memory_mb: 262144 memory_mb: 2048 name: \u0026quot;centos-tmp\u0026quot; nic_list { mac_addr: \u0026quot;50:6b:8d:79:1d:40\u0026quot; network_name: \u0026quot;Rx-Automation-Network\u0026quot; network_uuid: \u0026quot;ae60a809-d865-4a86-a925-efe062de8084\u0026quot; type: \u0026quot;kNormalNic\u0026quot; uuid: \u0026quot;4b57273d-fc5a-44a6-9791-4bed549c6ae3\u0026quot; vlan_mode: \u0026quot;kAccess\u0026quot; } num_cores_per_vcpu: 1 num_vcpus: 1 power_state_mechanism: \u0026quot;kHard\u0026quot; vga_console: True vm_type: \u0026quot;kGuestVM\u0026quot; } logical_timestamp: 3 state: \u0026quot;kOff\u0026quot; uuid: \u0026quot;336672c6-e4b9-4cfa-b8b3-392e66257fd8\u0026quot; } \u0026lt;acropolis\u0026gt;  使用以上命令得到测试模板机的磁盘文件的路径： vmdisk_nfs_path: \u0026quot;/SelfServiceContainer/.acropolis/vmdisk/35ae574b-725f-4ea8-977c-b5c9c42857ca\u0026quot;\n用 exit 命令退出 acli 命令行。退出 CVM 的SSH会话。\n使用SSH登录PC虚拟机 ssh nutanix@\u0026lt;pc_vm_ip_address\u0026gt;，之后运行nuclei命令行。\nimage.create name=CentOS7-Template1 image_type=DISK_IMAGE source_uri=nfs://10.21.11.37/SelfServiceContainer/.acropolis/vmdisk/35ae574b-725f-4ea8-977c-b5c9c42857ca   Image name: CentOS7-Template 这是自己起的镜像名称 CVM IP address: 10.21.11.37 这是AHV群集的Cluster IP vmdisk_nfs_path: /NTNX-Container/.acropolis/vmdisk/295b45d0-b8ba–4d52–97ef–54cc5b885af7 这个是acli的输出结果。  以上命令执行成功以后，在命令行里确认一下：\n\u0026lt;nuclei\u0026gt; image.list Name UUID State CentOS-7-1406-x86_64-DVD.iso 9236e75f-72f4-4e31-be29-a305159a8ac5 COMPLETE CentOS7-Template 679178b9-c482-4c30-933b-ed50ab03cb48 COMPLETE CentOSv2 eae6627d-1d34-4d30-9c8a-13ca546c444a COMPLETE Virt IO 8bfa2ebe-6c3b-4a4f-a024-6655f05625fd COMPLETE Windows2012-disk1 829ec164-ff39-4b79-a901-541e19fc3e2b COMPLETE server_2012_r2 fa95afb2-4f67-4748-a595-b3e8e4260fb5 COMPLETE \u0026lt;nuclei\u0026gt;  然后登陆到PC里面在网页上确认一下。如下图所示。\n以上步骤的验收标准： PC中可以看到这个镜像，可以将这个镜像加入服务目录中。 "
},
{
	"uri": "/01-prism-central/",
	"title": "Prism Central",
	"tags": [],
	"description": "PC的基础配置和部署",
	"content": "PC的部署需求：\n AHV群集已经安装部署完毕 AD的用户和组就绪 AHV的初始化配置完成 下载一键式的PC安装包  本文使用的一键式PC安装包如下所示：\n 5.5-prism_central.tar 5.5-prism_central_metadata.json   部署Prism Central 部署PC的安装包\n 配置Prism Central 完成PC的基础配置\n "
},
{
	"uri": "/06-ce/04-tips/",
	"title": "常用技巧",
	"tags": [],
	"description": "CE的相关常用命令",
	"content": " 这个lab的目标：\n 在硬件受限制的时候调整cvm的规格 调整时区和时间 其它  调整时区和日期相关 调整Host或者CVM操作系统的时区、日期和时间等。\n参考命令如下：\ntimedatectl set-timezone Asia/Shanghai timedatectl set-ntp true ntpq -p  调整CVM的内存 如果按照CE的机器内存很紧张，可以将CVM的内存降低，登陆到AHV的OS，参考命令如下：\nvirsh shutdown NTNX-7aa2dd30-A-CVM virsh setmaxmem NTNX-7aa2dd30-A-CVM 10G --config virsh setmem NTNX-7aa2dd30-A-CVM 10G --config virsh start NTNX-7aa2dd30-A-CVM virsh dominfo NTNX-7aa2dd30-A-CVM  "
},
{
	"uri": "/02-nucalm-basic/",
	"title": "Nutanix Calm基础功能",
	"tags": [],
	"description": "Nutanix Calm环境的基本配置和基础功能",
	"content": "  初始化配置Calm Calm环境的基础配置\n 导入Nutanix Calm商店里的蓝图 Calm里应用商店的初始化配置\n 配置服务目录 在自助服务的门户里，可以选择ISO和磁盘镜像\n 创建虚拟机模板 创建自定义的虚拟机模板\n "
},
{
	"uri": "/03-nucalm-middle/",
	"title": "Nutanix Calm中级功能",
	"tags": [],
	"description": "Nutanix Calm蓝图管理从简单到复杂",
	"content": "  HelloWorld蓝图 创建一个最简单的蓝图\n 三层LAMP应用蓝图 基于LAMP技术堆栈的典型三层应用\n 模拟AWS EC2蓝图 创建一个模拟AWS EC2服务的蓝图\n LAMP技术堆栈蓝图 创建带有负载均衡能力的LAMP(/images/服务的蓝图\n "
},
{
	"uri": "/04-nucalm-advance/",
	"title": "Nutanix Calm高级功能",
	"tags": [],
	"description": "Nutanix Calm蓝图管理从简单到复杂",
	"content": "  一键安装Docker Swarm群集 安装和部署Docker Swarm群集，包含高可用性等。\n Docker Datacenter使用DVP持久存储 安装和部署DDC，并使用DVP提供持久存储\n "
},
{
	"uri": "/05-k8s/",
	"title": "Nutanix K8S相关功能",
	"tags": [],
	"description": "K8S群集搭建和持久存储等",
	"content": "  一键安装K8S群集 安装和部署K8S群集，包含高可用性等。\n "
},
{
	"uri": "/06-ce/",
	"title": "Nutanix CE安装和使用",
	"tags": [],
	"description": "Nutanix CE的安装和管理",
	"content": "Nutanix Community Edition是100%的软件解决方案，不仅是免费的，而且还是功能齐全的Nutanix虚拟计算平台，其中包括“Acropolis”和“Prism”。使技术爱好者可以轻松地评估最新的融合技术，成本为零。此文档可以帮助你顺利地利用Nutanix CE搭建测试平台。\n 环境准备 准备安装CE所需要的硬件和网络环境\n 安装部署 在服务器上安装CE\n 常用功能操作 CE的最基本的操作和使用介绍\n 常用技巧 CE的相关常用命令\n "
},
{
	"uri": "/",
	"title": "Nutanix实验室",
	"tags": [],
	"description": "技术文档和操作手册",
	"content": " Nutanix实验室  Nutanix全球用户支持门户   Nutanix圣经   Nutanix中国官方微信公众号  ： Nutanix-China  本站点包含了Nutanix Calm和Nutanix CE等产品的部分操作指南，旨在帮助你了解Nutanix超融合技术，让你能够利用自己现有的设备和网络，轻松地搭建超融合体验环境。\n建议的安装Nutanix CE环境的服务器配置如下：\n 2路Intel Xeon （10+核）服务器 1块500+GB SSD硬盘 2块2+TB SATA硬盘 1块10GB 以太网卡 384GB内存  这样的四台服务器可以组成一个Nutanix超融合集群，推荐此配置的原因如下：\n 按1：6的CPU的整合比，该集群可以提供800vCPU 按2vCPU/4G RAM的规格计算，该集群可以运行超过350个此规格虚拟机 磁盘裸空间容量为10T，初始化以后可用的存储空间为5TB，打开压缩、去重等功能以后，在使用的过程中，该系统或将能够提供10TB以上的可用存储空间 可以满足150人左右的开发团队的资源需求，人均2个虚拟机。或者说运行350个虚拟机 如果有多个4节点集群，可以部署一套Prism Central进行统一管理，同时PC也能提供云平台自助服务和Calm自动化应用部署等高级功能。  以上的集群/资源池Nutanix提供社区支持服务，所使用的都是在社区论坛上可以下载到的软件。\nNutanix超融合的优势 上图是Gartner对HCI厂商的评测，Nutanix是HCI超融合基础架构的创立者，一直以来也在这个细分市场的保持着技术领先者的地位。2018年Garnter对HCI市场最新的分析报告显示如下：\nNutanix HCI主要的优势和评价：\n “行业领先的创新和可扩展架构，极大地领先于几乎所有其他竞争对手。” “Hypervisor选择方面的灵活性，基于KVM的AHV应用的比例逐渐提高，可以满足寻求比VMware ESXi更低成本的选择。” “已验证的用户认可度和很高的客户满意度，因此拥有很多大量节点数 (100+)的持续采购的全球大型企业。”  Nutanix提供免费下载和安装的社区版软件，任何人都可以安装并体验Nutanix超融合技术。\n社区版软件中包含了上图中的Prism（管理控制平面）和Acropolis（虚拟化和数据平面）。使用社区版软件，你可以轻松地搭建4节点的集群。并在集群里部署包含了Nutanix Calm功能的Prism Central，PC是统一管理多个集群的多云管理平台。它还内置 和集成了自助服务，容量规划，异常行为监测的监控等高级管理功能。\nCalm 简介 IT团队一直想方设法地整体提升IT的敏捷性，从而加速创新的步伐。然而，应用的开发和交付也在变得日益复杂，这使敏捷性更具有挑战性。部门墙增加了跨专业技术沟通的成本，削弱了实现业务价值的能力。\nCalm提供企业级应用编排，变革了IT团队管理应用和支持业务的工作模式。完全整合在Nutanix管理平台中的Calm，可以提供一个强大的通用型应用交付框架。不同的IT团队可以同时在这个平台上协作，进行快速的应用部署和持续交付。\nCalm将应用看做是一个整体来管理，而不仅是一些虚拟机，实现了应用的自动化创建、消费和访问控制。Calm能统一管理私有云和公有云等环境，实现了简洁的、可重复的应用自动化管理。\n如上图所示，Calm包含在Prism管理控制平面中，基于Prism中简洁高效的一键式运维，它协助企业从虚拟化资源池的运维，提升到以业务为中心的自动化应用运维。\n下图是Calm的可视化应用蓝图编辑器，它的主要功能如下所示：\n 应用生命周期管理：利用预定义的应用蓝图，全面地实现了传统型多层应用和流行的分布式服务的自动化运维，包括系统制备、扩缩容和资源释放等操作。应用蓝图将极大地简化了私有云和公有云的应用管理和运维。\n 应用蓝图管理：将应用系统的所有组成部分（包括相关的虚拟机、配置和可执行程序）融入到了一个可视化的、操作直观的蓝图里，从而简化了企业应用的配置管理和日常运维。应用蓝图提升了基础架构团队的管理效率。IT团队再也不用像以前那样，在应用管理的日常工作上花费大量时间。\n Nutanix应用市场：应用蓝图可以在Nutanix 应用市场（Marketplace）里把应用直接发布给最终用户，使产品经理和开发人员能够持续交付产品，快速地供给应用，及时地满足IT服务请求。\n 应用治理：Calm基于角色的访问控制机制可以限制用户的操作权限。此外，系统会集中地记录所有操作活动和变更，可以实现端到端的可追溯性，这些信息可以提供给安全团队，用来配合相关合规审核工作。\n 混合云管理：能在混合云的架构里，自动化地制备应用，包括AWS公有云环境，能实现多层应用和分布式应用的弹性扩缩容。Calm能全局统计资源用量，让您对公有云的实际消费成本一目了然，方便您按照业需求和预算做出合理的决策。\n  可以在社区下载ce-pc-deploy-2018.01.31.tar软件包，部署在ce-2018.01.31-stable.img的集群中测试和体验。\n术语 本网站里所使用的术语和缩略语：\n PC ： Prisum Central PE ： Prisum Element CE ： Nutanix Community  本站的变更日志  2018-1-22：增加了EC2服务高仿蓝图和LAMP堆栈自定义应用部署蓝图。 2018-2-11: 增加CE安装手册 2018-5-24：增加了几条CE使用技巧 修订了首页内容，修订了CE部分的内容  向本网站投稿 欢迎投稿关于Nutanix产品的技术文章。\n请发邮件到： martin.liu@nutanix.com 本网站的Web站点 这个站点使用了Hugo静态网站生成器加DocDock模板。所有源代码在Nutanix-lab/lab-guide  ；你可以下载到本地并参与修订。\n"
},
{
	"uri": "/_footer/",
	"title": "footer",
	"tags": [],
	"description": "",
	"content": "页脚说明\n"
},
{
	"uri": "/_header/",
	"title": "header",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/credits/",
	"title": "Credits",
	"tags": [],
	"description": "contributors and packages used by hugo-theme-docdock",
	"content": " Github contributors  Martin Liu https://martinliu.cn  "
},
{
	"uri": "/showcase/",
	"title": "Nutanix技术粉丝的展示厅",
	"tags": [],
	"description": "Hugo-built Sites with docdock theme",
	"content": " 提交您的网站链接给我，发邮件到 martin.liu@nutanix.com\nhttps://invincible.site/ 这是里应该是你的名字和网址链接 @shazic https://bitfan.io/ 这是里应该是你的名字和网址链接@vjeantet "
},
{
	"uri": "/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/01-prism-central/00-deploy-pc/",
	"title": "部署Prism Central",
	"tags": [],
	"description": "部署PC的安装包",
	"content": "在AHV群集的管理界面PE里，点击左上角的第一个方格里的链接 “Register or create new”，在弹出的界面里，点击界面下部的上传安装包的选项，选择如下的两个文件，上传的界面如下所示。\n上传的文件为：\n 5.5-prism_central.tar 5.5-prism_central_metadata.json  上传完毕之后点击安装按钮\n输入PC虚拟机的相关信息，如下图所示：\n注意可以勾选最下面的那个选项，把PC安装配置好之后一次性的把当前所操作的PE也一次性注册到PC中。 点击上图的部署按钮之后，大约需要半个小时的时间完成整个安装配置过程。\n在部署和配置PC的过程中，可以监控以下这两个任务的进度。\n安装部署完毕之后，在PE的界面中就可以看到PC的状态为OK。点击Launch链接。进入PC的登录界面，默认的用户名和密码是 admin / Nutanix/4u\n以上步骤的验收标准： 使用PC的默认用户名和密码成功登陆新安装的PC。 "
},
{
	"uri": "/01-prism-central/01-configure-pc/",
	"title": "配置Prism Central",
	"tags": [],
	"description": "完成PC的基础配置",
	"content": "用新修改的admin密码登录之后，点击右上角的问号按钮。点击下面的Self Service \u0026amp; Apps链接，进入SSP的初始化配置界面。\n点击界面上的New Directory 按钮，配置和AD的集成。\n在配置页面里输入AD的项目信息，下面的AD的域名为zenlab.local；点击Next按钮。 进入SSP管理员配置页面，点击 Add Admins 按钮。\n在输入框里输入 ssp_a 即可自动搜索出之前创建的SSP管理员组。也可以使用已经由的AD用户和组，点击 Save。\n在网络配置里勾选默认群集中供SSP用户使用的网络。之后点击 Next 。\n在最后一个页面中勾选 Enable App Management ，点击 Finish 完成SSP的配置和App功能的启用。 以上配置的生效需要一个过程，大约需要十分钟左右的时间，可以在任务里观察这个任务的状态。\n以上步骤的验收标准： 上图中Enable App Management的100%成功完成。 "
}]